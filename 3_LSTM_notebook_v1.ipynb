{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming we have training data\n",
    "# X_train is the input sequence data, y_train is the target data\n",
    "# 100 samples, sequence length of 6, 21 feature per time step\n",
    "X_train = torch.randn(100, 6, 21)\n",
    "# Target for each sample is 6 values, possibly for a regression task\n",
    "y_train = torch.randn(100, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `pack_padded_sequence`: Convert a padded tensor to a PackedSequence, compress the padded part, and pass it to RNN or LSTM for calculation. The model will not consider the padded part.\n",
    "* `pad_packed_sequence`: Restore the PackedSequence object to a standard tensor for subsequent processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x: tensor([[[ 1,  2],\n",
      "         [ 3,  4],\n",
      "         [ 0,  0]],\n",
      "\n",
      "        [[ 5,  6],\n",
      "         [ 7,  8],\n",
      "         [ 0,  0]],\n",
      "\n",
      "        [[ 9, 10],\n",
      "         [11, 12],\n",
      "         [13, 14]]])\n",
      "x_lengths: tensor([2, 2, 3])\n",
      "PackedSequence(data=tensor([[ 9, 10],\n",
      "        [ 1,  2],\n",
      "        [ 5,  6],\n",
      "        [11, 12],\n",
      "        [ 3,  4],\n",
      "        [ 7,  8],\n",
      "        [13, 14]]), batch_sizes=tensor([3, 3, 1]), sorted_indices=tensor([2, 0, 1]), unsorted_indices=tensor([1, 2, 0]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "# Assuming the input data is like this\n",
    "x = torch.tensor([[[1, 2], [3, 4], [0, 0]],  # Length 2\n",
    "                  [[5, 6], [7, 8], [0, 0]],  # Length 2\n",
    "                  [[9, 10], [11, 12], [13, 14]]])  # Length 3\n",
    "\n",
    "# x_lengths indicates the actual length of each sequence\n",
    "x_lengths = torch.tensor([2, 2, 3])\n",
    "\n",
    "print(\"Original x:\", x)\n",
    "print(\"x_lengths:\", x_lengths)\n",
    "\n",
    "# Use pack_padded_sequence to compress the padded sequences\n",
    "packed_x = pack_padded_sequence(x, x_lengths, batch_first=True, enforce_sorted=False)\n",
    "print(packed_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class StatePredictLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, varstate_size):\n",
    "        super(StatePredictLSTM, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.state_layer = nn.Linear(hidden_size, varstate_size)\n",
    "\n",
    "    def forward(self, x, x_lengths, h_state):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, hidden_size)\n",
    "\n",
    "        # Handle variable-length sequences\n",
    "        x = pack_padded_sequence(x, x_lengths, batch_first=True)\n",
    "        r_out, h_state = self.lstm(x, h_state)\n",
    "\n",
    "        # Convert the PackedSequence back to a regular Tensor\n",
    "        paded_out, _ = pad_packed_sequence(r_out, batch_first=True)\n",
    "\n",
    "        # Compute the output of the state_layer for each time step\n",
    "        state_outs = []\n",
    "        for time_step in range(paded_out.size(1)):  # Predict for each time step\n",
    "            state_outs.append(self.state_layer(paded_out[:, time_step, :]))\n",
    "\n",
    "        # Return the predicted results and the LSTM hidden state\n",
    "        return torch.stack(state_outs, dim=1), h_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (predictions):\n",
      "tensor([[[ 4.6051e-02, -5.1326e-02,  1.5498e-02, -9.5112e-03, -4.8703e-02,\n",
      "           1.5998e-02,  1.6308e-01],\n",
      "         [ 1.4444e-01,  1.1901e-02,  1.5310e-02,  7.5998e-02, -4.8189e-02,\n",
      "          -4.6561e-02,  5.3164e-02],\n",
      "         [ 7.9999e-02,  3.2026e-02,  3.9151e-02,  1.3521e-01, -2.3209e-05,\n",
      "          -4.1681e-02,  1.3888e-01],\n",
      "         [ 2.8237e-02,  3.4150e-02,  7.7798e-03,  1.1590e-01, -7.0034e-02,\n",
      "           3.9986e-02,  1.0915e-01],\n",
      "         [ 1.0844e-01,  2.6283e-02,  4.0038e-02,  1.2014e-01, -6.0351e-02,\n",
      "          -9.6238e-03,  3.0930e-02],\n",
      "         [ 5.4449e-02, -1.0091e-02, -8.1561e-03,  2.8222e-02,  6.2727e-03,\n",
      "           4.9855e-02,  1.1689e-01]],\n",
      "\n",
      "        [[ 7.1354e-02,  4.7599e-02,  2.5650e-02,  7.8342e-02, -8.6414e-02,\n",
      "          -5.3234e-05,  1.4454e-01],\n",
      "         [ 7.8583e-02,  1.9057e-02,  7.7142e-02,  1.5484e-02, -1.5784e-02,\n",
      "           2.2203e-02,  5.2135e-02],\n",
      "         [ 5.9223e-02, -4.2070e-03,  9.1932e-02, -2.0348e-03,  1.5848e-02,\n",
      "          -1.3450e-02,  3.7654e-02],\n",
      "         [ 8.0784e-02,  6.6058e-04,  4.8448e-02,  5.1919e-03, -7.3162e-02,\n",
      "          -6.1068e-03,  1.1772e-01],\n",
      "         [ 1.0520e-01,  3.3856e-02, -4.7143e-02, -5.8088e-02, -5.8913e-02,\n",
      "           2.8001e-02,  2.1625e-01],\n",
      "         [ 7.6132e-02,  1.9223e-02,  4.1851e-02,  7.6728e-02, -7.7261e-02,\n",
      "          -1.0801e-02,  1.2288e-01]],\n",
      "\n",
      "        [[ 1.1263e-01, -1.0967e-02,  1.3772e-02, -4.4004e-02, -9.3666e-03,\n",
      "          -2.2132e-02,  1.4037e-01],\n",
      "         [ 1.7713e-01,  5.7639e-02, -4.3216e-02,  3.3583e-02, -9.5633e-02,\n",
      "          -1.3747e-03,  6.0872e-02],\n",
      "         [ 9.1459e-02,  5.3892e-02, -3.6255e-02,  1.3581e-01, -1.0049e-01,\n",
      "           6.3863e-02,  1.3287e-01],\n",
      "         [ 5.9888e-02,  1.1656e-01, -4.3489e-02,  1.1553e-01, -7.1919e-02,\n",
      "           8.0147e-02,  1.3336e-01],\n",
      "         [ 7.6132e-02,  1.9223e-02,  4.1851e-02,  7.6728e-02, -7.7261e-02,\n",
      "          -1.0801e-02,  1.2288e-01],\n",
      "         [ 7.6132e-02,  1.9223e-02,  4.1851e-02,  7.6728e-02, -7.7261e-02,\n",
      "          -1.0801e-02,  1.2288e-01]],\n",
      "\n",
      "        [[ 1.2391e-01,  2.6872e-02,  4.4344e-02,  1.4117e-02, -1.1241e-01,\n",
      "          -6.6370e-02,  1.6866e-01],\n",
      "         [ 1.6703e-01,  2.0251e-02,  1.8311e-02, -2.6150e-02, -1.2675e-01,\n",
      "          -1.3546e-02,  1.1811e-01],\n",
      "         [ 1.2009e-01,  8.1595e-04,  6.2952e-02, -5.8075e-02, -3.7275e-02,\n",
      "          -4.5706e-02,  1.9244e-01],\n",
      "         [ 7.6132e-02,  1.9223e-02,  4.1851e-02,  7.6728e-02, -7.7261e-02,\n",
      "          -1.0801e-02,  1.2288e-01],\n",
      "         [ 7.6132e-02,  1.9223e-02,  4.1851e-02,  7.6728e-02, -7.7261e-02,\n",
      "          -1.0801e-02,  1.2288e-01],\n",
      "         [ 7.6132e-02,  1.9223e-02,  4.1851e-02,  7.6728e-02, -7.7261e-02,\n",
      "          -1.0801e-02,  1.2288e-01]]], grad_fn=<StackBackward0>)\n",
      "Loss: 1.0938456058502197\n",
      "Parameter containing:\n",
      "tensor([[ 0.0062,  0.0531,  0.1253,  ..., -0.0594,  0.0678,  0.0746],\n",
      "        [-0.0080, -0.0897,  0.1183,  ..., -0.0441, -0.0869,  0.0275],\n",
      "        [ 0.0845, -0.0277, -0.1159,  ...,  0.0663, -0.0400, -0.0369],\n",
      "        ...,\n",
      "        [ 0.0720, -0.1067,  0.0814,  ..., -0.0120, -0.0557,  0.1154],\n",
      "        [ 0.0982,  0.0144,  0.0801,  ...,  0.0673,  0.1204, -0.0171],\n",
      "        [-0.0832,  0.0757,  0.1204,  ...,  0.1207,  0.0784, -0.0984]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1198, -0.1236, -0.0725,  ..., -0.0540,  0.0885, -0.0210],\n",
      "        [-0.0932,  0.0044,  0.0390,  ...,  0.0652, -0.0989,  0.0016],\n",
      "        [ 0.0352,  0.0659, -0.0786,  ...,  0.0764, -0.0421,  0.0051],\n",
      "        ...,\n",
      "        [ 0.0221, -0.0439,  0.1159,  ...,  0.0026,  0.0128, -0.0225],\n",
      "        [-0.0356,  0.0245,  0.0840,  ..., -0.0770,  0.0850,  0.0364],\n",
      "        [ 0.1009, -0.0528,  0.0369,  ...,  0.0354, -0.0903, -0.0854]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0532,  0.1165,  0.0662, -0.0477,  0.1235, -0.0787, -0.0245,  0.0739,\n",
      "         0.0615,  0.1032, -0.0519,  0.0366, -0.1064,  0.0622, -0.1089, -0.1068,\n",
      "         0.0095,  0.0257, -0.0720, -0.0408,  0.1000, -0.0656, -0.1019, -0.0720,\n",
      "        -0.0725,  0.0530,  0.0407, -0.0809,  0.0922,  0.0246, -0.1142, -0.0136,\n",
      "         0.0370,  0.0514,  0.0056, -0.0187, -0.1036,  0.0582,  0.0658, -0.0959,\n",
      "        -0.0165,  0.0278, -0.0605,  0.0296, -0.0575, -0.0235, -0.0512,  0.1082,\n",
      "        -0.0409,  0.1085,  0.0379,  0.0097, -0.1229, -0.0664,  0.0525, -0.1185,\n",
      "        -0.1103, -0.0198, -0.0446, -0.0185,  0.0974,  0.0502,  0.1041,  0.0126,\n",
      "         0.1179,  0.1106, -0.0468, -0.0322, -0.0325,  0.0345, -0.0563,  0.0204,\n",
      "        -0.0337, -0.0645,  0.0435, -0.1188,  0.0959,  0.1021,  0.0958, -0.0746,\n",
      "        -0.0060, -0.0586,  0.0553, -0.0029,  0.1207,  0.0207, -0.0765, -0.0913,\n",
      "        -0.1069,  0.0917, -0.0913,  0.0053, -0.0291,  0.0053,  0.0980, -0.1228,\n",
      "        -0.1189,  0.0972, -0.1125,  0.0735,  0.0448,  0.0523, -0.0176, -0.0576,\n",
      "        -0.0657,  0.0643,  0.1074,  0.0642,  0.0503, -0.1066,  0.1166, -0.0824,\n",
      "         0.0176, -0.0576, -0.0594, -0.1182, -0.0372,  0.0573,  0.1083, -0.1109,\n",
      "         0.0283, -0.0647, -0.0721,  0.1047,  0.0220,  0.0701,  0.1051, -0.1175,\n",
      "        -0.0101,  0.0766, -0.1073,  0.0870, -0.0220, -0.1075, -0.1182, -0.0051,\n",
      "        -0.0031, -0.0311,  0.0506,  0.0161, -0.1085, -0.0035, -0.0292, -0.0771,\n",
      "         0.0827, -0.0708, -0.0808, -0.0600,  0.0825, -0.0622,  0.0301,  0.1064,\n",
      "        -0.0627,  0.0577, -0.0228,  0.0190, -0.1152,  0.1002, -0.0562, -0.0376,\n",
      "        -0.0324, -0.0363,  0.0355,  0.0945, -0.0183,  0.0059,  0.0764,  0.0335,\n",
      "        -0.0178,  0.0240,  0.0531, -0.0230,  0.0880,  0.0198,  0.1044,  0.0016,\n",
      "         0.1158,  0.0322,  0.1061, -0.0652,  0.0180,  0.1167, -0.0828,  0.0099,\n",
      "        -0.0064, -0.0825, -0.1084, -0.0098, -0.1179,  0.0658, -0.0495, -0.0507,\n",
      "        -0.1125, -0.0718, -0.0741, -0.1126,  0.0675, -0.0350,  0.0417, -0.1132,\n",
      "        -0.0718,  0.0863,  0.0480, -0.0545, -0.1128,  0.0831, -0.1201,  0.1013,\n",
      "        -0.0523, -0.0622,  0.0944, -0.0872, -0.0492,  0.0789,  0.1204, -0.0075,\n",
      "         0.0147, -0.0325,  0.1014,  0.0254,  0.0394,  0.0503, -0.0056,  0.0403,\n",
      "         0.0057,  0.0422,  0.0933,  0.0898, -0.0702, -0.0366,  0.0620,  0.0990,\n",
      "         0.0217,  0.0715, -0.0056, -0.0502,  0.0771, -0.0603,  0.0809,  0.0722,\n",
      "        -0.0467, -0.0164,  0.0265, -0.0179,  0.0133,  0.1256,  0.0069,  0.0176,\n",
      "        -0.0727, -0.0169,  0.0905, -0.1236,  0.0853, -0.0726,  0.0879, -0.0743],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0242, -0.0592, -0.0365, -0.0259, -0.1182,  0.1110,  0.1026, -0.0662,\n",
      "        -0.0516,  0.0562,  0.0923,  0.0857, -0.1190,  0.0330,  0.0314, -0.0106,\n",
      "         0.0944,  0.0557, -0.0684, -0.1109,  0.0601, -0.0978, -0.0536,  0.0802,\n",
      "         0.0888,  0.0063,  0.1238, -0.0780, -0.0798,  0.0516,  0.0066,  0.0016,\n",
      "         0.0413, -0.0507,  0.0186,  0.0581, -0.1009,  0.0773, -0.0671,  0.0816,\n",
      "        -0.0642, -0.0377,  0.0484,  0.1243, -0.1082, -0.1016, -0.0362,  0.0730,\n",
      "        -0.0039,  0.1138, -0.0606,  0.1027,  0.1105, -0.1089,  0.0665, -0.0378,\n",
      "         0.0881,  0.0300,  0.1198,  0.0356,  0.0405, -0.0844,  0.0489,  0.0860,\n",
      "         0.0237, -0.0533,  0.0506,  0.1226, -0.0034,  0.0076, -0.0476,  0.0754,\n",
      "         0.0431, -0.0007, -0.0365, -0.0326,  0.1236,  0.1061, -0.0487, -0.0367,\n",
      "         0.1036, -0.1226, -0.1002,  0.0818, -0.0735,  0.1178,  0.1103,  0.0661,\n",
      "        -0.0526,  0.0822, -0.0981, -0.0113, -0.0019, -0.0654,  0.1150, -0.0073,\n",
      "        -0.0389, -0.0434,  0.0589, -0.0945,  0.0529, -0.0384, -0.0990,  0.0515,\n",
      "         0.0194,  0.0763, -0.0172, -0.0212, -0.0670,  0.0265, -0.0925, -0.0831,\n",
      "         0.0454, -0.1114, -0.1133,  0.1022, -0.1077, -0.1087, -0.0128,  0.0531,\n",
      "        -0.1059,  0.0912, -0.0872,  0.1115,  0.0427,  0.0792, -0.0226,  0.0525,\n",
      "        -0.1059,  0.0657, -0.0211,  0.0890,  0.1049, -0.1068, -0.0949,  0.0153,\n",
      "        -0.0791,  0.0907, -0.0573, -0.0258, -0.0162,  0.0331,  0.1082, -0.1009,\n",
      "        -0.0322,  0.0950,  0.0340, -0.1110,  0.0452,  0.0503, -0.1061, -0.0036,\n",
      "         0.1017, -0.0038,  0.1093,  0.0270,  0.0129, -0.0648,  0.0548, -0.1158,\n",
      "         0.0600,  0.0695, -0.0331,  0.1053,  0.1194,  0.0565,  0.0749,  0.0819,\n",
      "         0.0475,  0.1236, -0.0393,  0.0945,  0.0932, -0.1010,  0.0747,  0.0983,\n",
      "         0.0962,  0.1156,  0.0157, -0.0461,  0.0029,  0.1211, -0.0765,  0.0896,\n",
      "        -0.0396,  0.0059, -0.0081,  0.0051,  0.0273,  0.0931, -0.0100,  0.0625,\n",
      "         0.0823, -0.1199,  0.0457, -0.0718, -0.0763,  0.1103,  0.0215, -0.1166,\n",
      "        -0.0870, -0.0997, -0.0213,  0.0101, -0.0565, -0.1153,  0.0523, -0.0922,\n",
      "         0.0868,  0.0697, -0.0392,  0.0287,  0.0403, -0.0365, -0.0331, -0.0237,\n",
      "         0.0195,  0.0431,  0.1144,  0.0875,  0.0143,  0.1061,  0.0486,  0.0003,\n",
      "        -0.0231,  0.0503, -0.0116, -0.1176, -0.0665, -0.1179, -0.0466, -0.1052,\n",
      "         0.0759, -0.0914,  0.0140, -0.0083,  0.0249, -0.0505, -0.1231, -0.0212,\n",
      "        -0.0589, -0.0842,  0.0225, -0.0950,  0.0627, -0.0781,  0.0135,  0.1081,\n",
      "         0.0503,  0.0328,  0.0174, -0.1008,  0.0827,  0.0752, -0.0042, -0.0113],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1057, -0.0272, -0.0904,  0.0631,  0.0183,  0.0686,  0.0503, -0.0953,\n",
      "         -0.0140,  0.1194,  0.0028,  0.0516, -0.0446,  0.0976,  0.0588, -0.0771,\n",
      "         -0.1185,  0.0135,  0.0973, -0.0835, -0.1223, -0.0944, -0.0572, -0.0899,\n",
      "         -0.0028, -0.0132,  0.0704, -0.1023, -0.0072,  0.0568, -0.1121, -0.0507,\n",
      "          0.0026,  0.0590, -0.0304,  0.0930, -0.0661,  0.1137,  0.0702, -0.1218,\n",
      "         -0.0371, -0.0592, -0.0996, -0.0299, -0.0228, -0.0628,  0.0866, -0.1153,\n",
      "          0.0535,  0.0057,  0.0274, -0.0734,  0.0769,  0.0276, -0.0330, -0.1054,\n",
      "         -0.0866, -0.0304, -0.0027, -0.0624,  0.0156, -0.0125,  0.0063,  0.0966],\n",
      "        [-0.1035,  0.0112,  0.0974,  0.0578,  0.0114,  0.1229,  0.0032, -0.0417,\n",
      "          0.0132,  0.1155,  0.0135,  0.0810, -0.0263,  0.0277,  0.0122,  0.0704,\n",
      "         -0.0957, -0.1004, -0.0319, -0.0934, -0.0038,  0.1019, -0.0189,  0.0046,\n",
      "         -0.0751, -0.0221,  0.0625,  0.0555,  0.0691, -0.0031, -0.0588,  0.0309,\n",
      "         -0.0731, -0.0374, -0.1145,  0.0619,  0.0848, -0.0166,  0.0669,  0.1118,\n",
      "          0.0758, -0.1174, -0.0716, -0.0670,  0.0298,  0.0316,  0.0498, -0.0011,\n",
      "         -0.0545, -0.0798,  0.1030,  0.0432,  0.0169,  0.1187, -0.0272, -0.0805,\n",
      "         -0.0306, -0.0300, -0.0103,  0.1106, -0.0126, -0.0977,  0.0276,  0.1007],\n",
      "        [ 0.0744,  0.0863, -0.0547, -0.0161, -0.0605, -0.0534,  0.0854,  0.0232,\n",
      "          0.0262,  0.0266,  0.0301, -0.1218,  0.0594,  0.0355, -0.1050, -0.0828,\n",
      "          0.0223,  0.0009, -0.0739,  0.0140, -0.0294,  0.0505,  0.0164,  0.0774,\n",
      "          0.0449,  0.1211, -0.0007, -0.0897,  0.1199,  0.0959, -0.0628,  0.1173,\n",
      "         -0.1239, -0.0957,  0.0933,  0.0739, -0.0961, -0.1260,  0.1010, -0.1111,\n",
      "          0.1174,  0.1233, -0.0383, -0.0012, -0.0398, -0.0236,  0.0949,  0.0884,\n",
      "         -0.0830, -0.0343, -0.0468, -0.0430,  0.1234, -0.1113,  0.0070,  0.0636,\n",
      "         -0.1066, -0.0563,  0.0754,  0.0178, -0.1055, -0.1171,  0.0992, -0.1184],\n",
      "        [ 0.1215,  0.0941,  0.0363,  0.0402,  0.0453,  0.0287,  0.0402, -0.0036,\n",
      "         -0.0587,  0.1076,  0.0955,  0.0473,  0.1013, -0.0995,  0.0426,  0.1015,\n",
      "         -0.0651,  0.1214,  0.1070,  0.0069, -0.1212,  0.1093,  0.0816,  0.0298,\n",
      "          0.1009, -0.0773,  0.0767,  0.0916,  0.0700, -0.0511,  0.0391,  0.0787,\n",
      "          0.0630, -0.1166, -0.0996, -0.0718,  0.0534,  0.0760, -0.0400, -0.1001,\n",
      "         -0.0215, -0.1210, -0.0688,  0.0757, -0.0145,  0.0454, -0.0441, -0.0361,\n",
      "          0.0674, -0.0971,  0.0469, -0.1158,  0.1145,  0.0227, -0.1187,  0.0519,\n",
      "         -0.0875,  0.1187, -0.0269, -0.0370, -0.0196,  0.0311, -0.0603,  0.1210],\n",
      "        [ 0.0379, -0.1024,  0.0209, -0.0780,  0.0886, -0.0009, -0.0179,  0.1110,\n",
      "         -0.0170, -0.0003, -0.0044, -0.1112,  0.0546, -0.1233,  0.0931, -0.1106,\n",
      "          0.0976, -0.0494,  0.0052,  0.0054, -0.1169,  0.0684, -0.0297,  0.0828,\n",
      "         -0.0053, -0.0608,  0.1197, -0.0582, -0.0553,  0.0535, -0.0934,  0.0164,\n",
      "         -0.0104, -0.1183,  0.0514,  0.0231,  0.0246,  0.0796,  0.0626, -0.0018,\n",
      "          0.0660,  0.0004, -0.0460,  0.0300,  0.0826, -0.0684,  0.0412,  0.0865,\n",
      "          0.0647, -0.0817, -0.0580,  0.0336, -0.0455, -0.1157,  0.0310, -0.0645,\n",
      "         -0.0362,  0.0557,  0.1116, -0.0441,  0.0129,  0.0630,  0.0316, -0.0465],\n",
      "        [ 0.0210, -0.0524,  0.0937,  0.1129, -0.0573,  0.1029, -0.0613,  0.0858,\n",
      "          0.0181,  0.0808, -0.0697,  0.1177, -0.0928, -0.1171,  0.0357,  0.0635,\n",
      "         -0.0536, -0.0731, -0.0423, -0.0450,  0.1068, -0.1212,  0.0472,  0.0313,\n",
      "         -0.0195, -0.0210, -0.0706, -0.0876,  0.0720, -0.0868,  0.0204, -0.0257,\n",
      "          0.0391, -0.0308, -0.0220,  0.0846,  0.1078,  0.1047, -0.0575,  0.0570,\n",
      "          0.0929, -0.1235,  0.0181,  0.0240,  0.0665,  0.0141,  0.0055, -0.0831,\n",
      "          0.0102,  0.0353, -0.0507,  0.1074, -0.1056,  0.0427,  0.0582, -0.0250,\n",
      "         -0.0489, -0.1095, -0.1237,  0.0541,  0.1084,  0.1132,  0.0036,  0.1229],\n",
      "        [ 0.0779, -0.0357,  0.0421,  0.0239, -0.0775, -0.0007, -0.0706, -0.1242,\n",
      "          0.0631, -0.0775,  0.1015,  0.0717, -0.0769, -0.0504, -0.0356, -0.0322,\n",
      "          0.0457,  0.0552, -0.1078, -0.0691, -0.0382,  0.0430,  0.0778,  0.0127,\n",
      "          0.0122, -0.0786, -0.0124, -0.0906, -0.0594, -0.0962, -0.0967, -0.1150,\n",
      "         -0.0499, -0.0050, -0.1216, -0.1241,  0.1235,  0.0240,  0.0940, -0.1190,\n",
      "          0.1048, -0.0481,  0.0549,  0.0380, -0.0008, -0.0940, -0.1160,  0.0317,\n",
      "         -0.1064, -0.1029,  0.0353, -0.1043, -0.0709, -0.0830,  0.0379,  0.0570,\n",
      "          0.1057,  0.0941, -0.0356, -0.1010,  0.0615,  0.0935, -0.1246, -0.1105]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0751,  0.0202,  0.0409,  0.0757, -0.0783, -0.0118,  0.1219],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Assume input size is 5 (input_size), hidden state size is 10 (hidden_size),\n",
    "# state variable size is 2 (varstate_size)\n",
    "input_size = 21\n",
    "hidden_size = 64\n",
    "varstate_size = 7\n",
    "batch_size = 4\n",
    "max_sequence_length = 6\n",
    "\n",
    "# Create fake training data X_train (batch_size, sequence_length, input_size)\n",
    "# The input is random numbers\n",
    "X_train = torch.randn(batch_size, max_sequence_length, input_size)\n",
    "\n",
    "# Create fake target data y_train (batch_size, sequence_length, varstate_size)\n",
    "# The target is also random numbers\n",
    "y_train = torch.randn(batch_size, max_sequence_length, varstate_size)\n",
    "\n",
    "# Define the actual lengths of the sequences\n",
    "# Assume each sequence has a different length\n",
    "x_lengths = torch.tensor([6, 5, 4, 3])\n",
    "\n",
    "# Initialize the model\n",
    "model = StatePredictLSTM(input_size=input_size, hidden_size=hidden_size, varstate_size=varstate_size)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the loss function (using mean squared error)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Forward pass: compute the model output\n",
    "h_state = (torch.zeros(1, batch_size, hidden_size), torch.zeros(1, batch_size, hidden_size))  # Initialize the hidden state\n",
    "output, _ = model(X_train, x_lengths, h_state)\n",
    "\n",
    "# Print the output\n",
    "print(\"Model output (predictions):\")\n",
    "print(output)\n",
    "\n",
    "# Compute the loss\n",
    "loss = criterion(output, y_train)\n",
    "print(\"Loss:\", loss.item())\n",
    "\n",
    "# Backward pass: compute gradients and update parameters\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Print the updated model parameters\n",
    "for param in model.parameters():\n",
    "    print(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
