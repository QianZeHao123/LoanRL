{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data Loading and Preprocessing**:\n",
    "   - Loads the data from a CSV file and standardizes specific columns (such as loan information, user states, etc.) for model training.\n",
    "   - Creates a new feature `installment_timestep` based on `loan_id` and `installment`.\n",
    "\n",
    "2. **Data Splitting**:\n",
    "   - Splits the data into training (`train`) and testing (`test`) sets based on the `sample` and `group` columns.\n",
    "\n",
    "3. **Feature and Label Preparation**:\n",
    "   - For each `loan_id`, extracts features and labels.\n",
    "   - Features include `loan_id`, user states, loan information, etc.\n",
    "   - Labels correspond to the next time step of the relevant state variables (e.g., prediction of `installment`).\n",
    "\n",
    "4. **Data Saving and Batching**:\n",
    "   - Saves the processed data as CSV files and stores the data in multiple batches by `loan_id` into pickle files for later training.\n",
    "\n",
    "5. **Training and Validation Split**:\n",
    "   - Randomly selects 10% of the training data as a validation set and the rest as the training set.\n",
    "\n",
    "The ultimate goal of this code is to save the processed data in a format suitable for training, ensuring that the data is standardized, properly split, and stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./Data/20240205fullsample_new.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show data summary\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show data columns names\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['installment_timestep'] = data.groupby(\n",
    "    ['loan_id', 'installment']).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['installment', 'installment_timestep', 'state_cum_overduelength',\n",
    "          'remaining_debt', 'state_capital', 'state_interests',\n",
    "          'state_penalty', 'gender', 'age',\n",
    "          'amount', 'num_loan', 'duration',\n",
    "          'year_ratio', 'diff_city', 'marriage',\n",
    "          'kids', 'month_in', 'housing',\n",
    "          'edu', 'motivation']\n",
    "\n",
    "data[states] = (data[states] - data[states].mean()) / data[states].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rlsim = data[data['sample'] == 'rlsimulator']\n",
    "data_rlsim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.loc[(data['sample'] == 'rlsimulator')\n",
    "                 & (data['group'] == 'train')]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.loc[(data['sample'] == 'rlsimulator')\n",
    "                & (data['group'] == 'test')]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list = [train, test]\n",
    "# data_name_list = ['train', 'test']\n",
    "data_list = [test]\n",
    "data_name_list = ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# varstate_size = 7\n",
    "\n",
    "\n",
    "for j in tqdm(range(len(data_list)), leave=True):\n",
    "    dt = data_list[j]\n",
    "    dt_loan_ids = dt['loan_id'].drop_duplicates().tolist()\n",
    "\n",
    "    X_df = pd.DataFrame()\n",
    "    y_df = pd.DataFrame()\n",
    "\n",
    "    for loan_id in tqdm(dt_loan_ids, leave=True):\n",
    "        df1 = dt.loc[dt['loan_id'] == loan_id]\n",
    "\n",
    "        X_train = df1[['loan_id'] + states + ['action_num_actual',\n",
    "                                              'installment_done',\n",
    "                                              'loan_done',\n",
    "                                              'recovery_rate_weighted']]\n",
    "        # X_train = X_train[:-1]\n",
    "        # X_df = X_df.append(X_train, ignore_index=True)\n",
    "        X_df = pd.concat([X_df, X_train], ignore_index=True)\n",
    "\n",
    "        # y_train: pd.DataFrame = df1[states[:varstate_size]]\n",
    "        y_train: pd.DataFrame = df1[['installment', 'installment_timestep', 'state_cum_overduelength',\n",
    "                                    'remaining_debt', 'state_capital', 'state_interests', 'state_penalty']]\n",
    "\n",
    "        y_train = y_train.rename(columns={'installment': 'installment.1',\n",
    "                                          'installment_timestep': 'installment_timestep.1',\n",
    "                                          'state_cum_overduelength': 'state_cum_overduelength.1',\n",
    "                                          'remaining_debt': 'remaining_debt.1',\n",
    "                                          'state_capital': 'state_capital.1',\n",
    "                                          'state_interests': 'state_interests.1',\n",
    "                                          'state_penalty': 'state_penalty.1'})\n",
    "\n",
    "        if y_train.shape[0] > 1:\n",
    "            y_train = y_train[1:]\n",
    "            # y_train = y_train.append(y_train.iloc[-1], ignore_index=True)\n",
    "            y_train = pd.concat(\n",
    "                [y_train, y_train.iloc[[-1]]], ignore_index=True)\n",
    "\n",
    "        # y_df = y_df.append(y_train, ignore_index=True)\n",
    "        y_df = pd.concat([y_df, y_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# create a directory to save the data\n",
    "save_folder = './Res/Data/Test'\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "X_df.to_csv(f'{save_folder}/X_df.csv', index=False)\n",
    "y_df.to_csv(f'{save_folder}/y_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
